{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import librosa\n",
    "import torchaudio\n",
    "import torchaudio.transforms as AT\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from covidxdataset import COVIDxDataset, COVIDxDataset2\n",
    "from audiodataset import CoswaraDataset, ConcatDataset, CoswaraDataset2, CoswaraDataset3, ConcatDataset_pair\n",
    "import util as util\n",
    "from util import Mel2Samp\n",
    "from train import train, validation, mm_train, mm_pair_train, mm_pair_valid\n",
    "from model import transfer_resNet, ResNet54, ResNet22, ResNet38, resnet50, MMNet, CLS\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio\n",
    "a_model = transfer_resNet(2)\n",
    "# a_model = ResNet22(2)\n",
    "\n",
    "# image\n",
    "i_model = resnet50()\n",
    "num_ftrs = i_model.fc.in_features\n",
    "i_model.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "i_model.fc = nn.Linear(num_ftrs, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_model.load_state_dict(torch.load('model/save3/a_model_0.830_0.955'))\n",
    "i_model.load_state_dict(torch.load('model/save3/i_model_0.830_0.955'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmnet = MMNet(a_model, i_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mmnet.state_dict(), './model/mmnet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('mels_full.npz', allow_pickle=True)\n",
    "aX, ay = data['x'], data['y']\n",
    "data = np.load('images_tr_full.npz', allow_pickle=True)\n",
    "iX_tr, y_tr = data['x'], data['y']\n",
    "data = np.load('images_test.npz', allow_pickle=True)\n",
    "iX_te, y_te = data['x'], data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train audio examples =  1886 [1753  133]\n",
      "train image examples =  1886 [1753  133]\n",
      "Class P :  3090698  N :  466298\n",
      "test audio examples =  472 [439  33]\n",
      "test image examples =  472 [439  33]\n",
      "ImageEpoch: 1\tSample:    1/35376\tLoss:1809.6594\tAccuracy:0.56\n",
      "AudioEpoch: 1\tSample:    1/35376\tLoss:1809.6594\tAccuracy:0.86\n",
      "Training Image\n",
      " SUMMARY EPOCH: 1\tSample:35376/35376\tLoss:180.6439\tAccuracy:0.99\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 1\tSample:35376/35376\tLoss:180.6439\tAccuracy:0.94\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3177e+04 1.2000e+01]\n",
      " [2.1870e+03 0.0000e+00]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH: 1\tSample:  472/  472\tLoss:0.2023\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 18.  15.]]\n",
      "save!!\n",
      "ImageEpoch: 2\tSample:    1/35376\tLoss:129.5409\tAccuracy:1.00\n",
      "AudioEpoch: 2\tSample:    1/35376\tLoss:129.5409\tAccuracy:0.95\n",
      "Training Image\n",
      " SUMMARY EPOCH: 2\tSample:35376/35376\tLoss:111.7096\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 2\tSample:35376/35376\tLoss:111.7096\tAccuracy:0.93\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[33072.     0.]\n",
      " [ 2304.     0.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH: 2\tSample:  472/  472\tLoss:0.3156\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 25.   8.]]\n",
      "save!!\n",
      "ImageEpoch: 3\tSample:    1/35376\tLoss:96.4016\tAccuracy:1.00\n",
      "AudioEpoch: 3\tSample:    1/35376\tLoss:96.4016\tAccuracy:0.93\n",
      "Training Image\n",
      " SUMMARY EPOCH: 3\tSample:35376/35376\tLoss:104.5964\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 3\tSample:35376/35376\tLoss:104.5964\tAccuracy:0.94\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3101e+04 5.0000e+00]\n",
      " [2.1980e+03 7.2000e+01]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH: 3\tSample:  472/  472\tLoss:0.2132\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 15.  18.]]\n",
      "save!!\n",
      "ImageEpoch: 4\tSample:    1/35376\tLoss:89.4759\tAccuracy:1.00\n",
      "AudioEpoch: 4\tSample:    1/35376\tLoss:89.4759\tAccuracy:0.96\n",
      "Training Image\n",
      " SUMMARY EPOCH: 4\tSample:35376/35376\tLoss:91.7196\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 4\tSample:35376/35376\tLoss:91.7196\tAccuracy:0.96\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[32859.   172.]\n",
      " [ 1374.   971.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH: 4\tSample:  472/  472\tLoss:0.2819\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 19.  14.]]\n",
      "save!!\n",
      "Epoch     4: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch     4: reducing learning rate of group 0 to 2.5000e-05.\n",
      "ImageEpoch: 5\tSample:    1/35376\tLoss:99.0294\tAccuracy:1.00\n",
      "AudioEpoch: 5\tSample:    1/35376\tLoss:99.0294\tAccuracy:0.91\n",
      "Training Image\n",
      " SUMMARY EPOCH: 5\tSample:35376/35376\tLoss:82.4982\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 5\tSample:35376/35376\tLoss:82.4982\tAccuracy:0.97\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[32857.   158.]\n",
      " [  956.  1405.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH: 5\tSample:  472/  472\tLoss:0.2440\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[438.   1.]\n",
      " [ 18.  15.]]\n",
      "save!!\n",
      "ImageEpoch: 6\tSample:    1/35376\tLoss:83.5110\tAccuracy:1.00\n",
      "AudioEpoch: 6\tSample:    1/35376\tLoss:83.5110\tAccuracy:0.99\n",
      "Training Image\n",
      " SUMMARY EPOCH: 6\tSample:35376/35376\tLoss:84.0150\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 6\tSample:35376/35376\tLoss:84.0150\tAccuracy:0.97\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[32809.   164.]\n",
      " [  865.  1538.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH: 6\tSample:  472/  472\tLoss:0.2850\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 19.  14.]]\n",
      "save!!\n",
      "ImageEpoch: 7\tSample:    1/35376\tLoss:73.3134\tAccuracy:1.00\n",
      "AudioEpoch: 7\tSample:    1/35376\tLoss:73.3134\tAccuracy:0.97\n",
      "Training Image\n",
      " SUMMARY EPOCH: 7\tSample:35376/35376\tLoss:76.4852\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 7\tSample:35376/35376\tLoss:76.4852\tAccuracy:0.98\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[32938.   124.]\n",
      " [  745.  1569.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH: 7\tSample:  472/  472\tLoss:0.4527\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 23.  10.]]\n",
      "save!!\n",
      "Epoch     7: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Epoch     7: reducing learning rate of group 0 to 1.2500e-05.\n",
      "ImageEpoch: 8\tSample:    1/35376\tLoss:83.9130\tAccuracy:1.00\n",
      "AudioEpoch: 8\tSample:    1/35376\tLoss:83.9130\tAccuracy:0.96\n",
      "Training Image\n",
      " SUMMARY EPOCH: 8\tSample:35376/35376\tLoss:74.1183\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 8\tSample:35376/35376\tLoss:74.1183\tAccuracy:0.98\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[32919.    98.]\n",
      " [  595.  1764.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH: 8\tSample:  472/  472\tLoss:0.4028\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 22.  11.]]\n",
      "save!!\n",
      "ImageEpoch: 9\tSample:    1/35376\tLoss:74.5456\tAccuracy:1.00\n",
      "AudioEpoch: 9\tSample:    1/35376\tLoss:74.5456\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH: 9\tSample:35376/35376\tLoss:70.1262\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 9\tSample:35376/35376\tLoss:70.1262\tAccuracy:0.98\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[32945.    84.]\n",
      " [  457.  1890.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH: 9\tSample:  472/  472\tLoss:0.3104\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "ImageEpoch:10\tSample:    1/35376\tLoss:74.1791\tAccuracy:1.00\n",
      "AudioEpoch:10\tSample:    1/35376\tLoss:74.1791\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:10\tSample:35376/35376\tLoss:68.4146\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:10\tSample:35376/35376\tLoss:68.4146\tAccuracy:0.99\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[32974.    82.]\n",
      " [  382.  1938.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:10\tSample:  472/  472\tLoss:0.2919\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 20.  13.]]\n",
      "save!!\n",
      "Epoch    10: reducing learning rate of group 0 to 6.2500e-06.\n",
      "Epoch    10: reducing learning rate of group 0 to 6.2500e-06.\n",
      "ImageEpoch:11\tSample:    1/35376\tLoss:63.5602\tAccuracy:1.00\n",
      "AudioEpoch:11\tSample:    1/35376\tLoss:63.5602\tAccuracy:0.99\n",
      "Training Image\n",
      " SUMMARY EPOCH:11\tSample:35376/35376\tLoss:68.0435\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:11\tSample:35376/35376\tLoss:68.0435\tAccuracy:0.99\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[32918.    72.]\n",
      " [  278.  2108.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:11\tSample:  472/  472\tLoss:0.3749\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "ImageEpoch:12\tSample:    1/35376\tLoss:72.0689\tAccuracy:1.00\n",
      "AudioEpoch:12\tSample:    1/35376\tLoss:72.0689\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:12\tSample:35376/35376\tLoss:67.3143\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:12\tSample:35376/35376\tLoss:67.3143\tAccuracy:0.99\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[32991.    56.]\n",
      " [  247.  2082.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:12\tSample:  472/  472\tLoss:0.3311\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 20.  13.]]\n",
      "save!!\n",
      "ImageEpoch:13\tSample:    1/35376\tLoss:65.3770\tAccuracy:1.00\n",
      "AudioEpoch:13\tSample:    1/35376\tLoss:65.3770\tAccuracy:0.99\n",
      "Training Image\n",
      " SUMMARY EPOCH:13\tSample:35376/35376\tLoss:64.8628\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:13\tSample:35376/35376\tLoss:64.8628\tAccuracy:0.99\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[33022.    39.]\n",
      " [  194.  2121.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:13\tSample:  472/  472\tLoss:0.2663\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 18.  15.]]\n",
      "save!!\n",
      "Epoch    13: reducing learning rate of group 0 to 3.1250e-06.\n",
      "Epoch    13: reducing learning rate of group 0 to 3.1250e-06.\n",
      "ImageEpoch:14\tSample:    1/35376\tLoss:62.7528\tAccuracy:1.00\n",
      "AudioEpoch:14\tSample:    1/35376\tLoss:62.7528\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:14\tSample:35376/35376\tLoss:64.6991\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:14\tSample:35376/35376\tLoss:64.6991\tAccuracy:0.99\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[33015.    40.]\n",
      " [  179.  2142.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:14\tSample:  472/  472\tLoss:0.3570\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "ImageEpoch:15\tSample:    1/35376\tLoss:68.0247\tAccuracy:1.00\n",
      "AudioEpoch:15\tSample:    1/35376\tLoss:68.0247\tAccuracy:0.99\n",
      "Training Image\n",
      " SUMMARY EPOCH:15\tSample:35376/35376\tLoss:63.2452\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:15\tSample:35376/35376\tLoss:63.2452\tAccuracy:0.99\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[33097.    42.]\n",
      " [  149.  2088.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:15\tSample:  472/  472\tLoss:0.4147\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 23.  10.]]\n",
      "save!!\n",
      "ImageEpoch:16\tSample:    1/35376\tLoss:69.5478\tAccuracy:1.00\n",
      "AudioEpoch:16\tSample:    1/35376\tLoss:69.5478\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:16\tSample:35376/35376\tLoss:64.1785\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:16\tSample:35376/35376\tLoss:64.1785\tAccuracy:0.99\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[32927.    34.]\n",
      " [  148.  2267.]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:16\tSample:  472/  472\tLoss:0.4278\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 23.  10.]]\n",
      "save!!\n",
      "Epoch    16: reducing learning rate of group 0 to 1.5625e-06.\n",
      "Epoch    16: reducing learning rate of group 0 to 1.5625e-06.\n",
      "ImageEpoch:17\tSample:    1/35376\tLoss:67.9113\tAccuracy:1.00\n",
      "AudioEpoch:17\tSample:    1/35376\tLoss:67.9113\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:17\tSample:35376/35376\tLoss:64.3208\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:17\tSample:35376/35376\tLoss:64.3208\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3019e+04 3.3000e+01]\n",
      " [1.2600e+02 2.1980e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:17\tSample:  472/  472\tLoss:0.3572\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 22.  11.]]\n",
      "save!!\n",
      "ImageEpoch:18\tSample:    1/35376\tLoss:75.2863\tAccuracy:1.00\n",
      "AudioEpoch:18\tSample:    1/35376\tLoss:75.2863\tAccuracy:0.97\n",
      "Training Image\n",
      " SUMMARY EPOCH:18\tSample:35376/35376\tLoss:63.2809\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:18\tSample:35376/35376\tLoss:63.2809\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3024e+04 3.2000e+01]\n",
      " [1.1300e+02 2.2070e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:18\tSample:  472/  472\tLoss:0.3361\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 20.  13.]]\n",
      "save!!\n",
      "ImageEpoch:19\tSample:    1/35376\tLoss:68.2810\tAccuracy:1.00\n",
      "AudioEpoch:19\tSample:    1/35376\tLoss:68.2810\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:19\tSample:35376/35376\tLoss:63.0101\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:19\tSample:35376/35376\tLoss:63.0101\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.2969e+04 2.3000e+01]\n",
      " [1.1000e+02 2.2740e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:19\tSample:  472/  472\tLoss:0.3837\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 22.  11.]]\n",
      "save!!\n",
      "Epoch    19: reducing learning rate of group 0 to 7.8125e-07.\n",
      "Epoch    19: reducing learning rate of group 0 to 7.8125e-07.\n",
      "ImageEpoch:20\tSample:    1/35376\tLoss:61.9625\tAccuracy:1.00\n",
      "AudioEpoch:20\tSample:    1/35376\tLoss:61.9625\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:20\tSample:35376/35376\tLoss:62.0602\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:20\tSample:35376/35376\tLoss:62.0602\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.2981e+04 2.4000e+01]\n",
      " [7.7000e+01 2.2940e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:20\tSample:  472/  472\tLoss:0.3824\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 22.  11.]]\n",
      "save!!\n",
      "ImageEpoch:21\tSample:    1/35376\tLoss:64.9592\tAccuracy:1.00\n",
      "AudioEpoch:21\tSample:    1/35376\tLoss:64.9592\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:21\tSample:35376/35376\tLoss:61.9710\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:21\tSample:35376/35376\tLoss:61.9710\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.300e+04 2.400e+01]\n",
      " [1.040e+02 2.248e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:21\tSample:  472/  472\tLoss:0.3954\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 23.  10.]]\n",
      "save!!\n",
      "ImageEpoch:22\tSample:    1/35376\tLoss:63.1865\tAccuracy:1.00\n",
      "AudioEpoch:22\tSample:    1/35376\tLoss:63.1865\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:22\tSample:35376/35376\tLoss:62.4721\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:22\tSample:35376/35376\tLoss:62.4721\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3023e+04 2.5000e+01]\n",
      " [8.0000e+01 2.2480e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:22\tSample:  472/  472\tLoss:0.3792\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 22.  11.]]\n",
      "save!!\n",
      "Epoch    22: reducing learning rate of group 0 to 3.9063e-07.\n",
      "Epoch    22: reducing learning rate of group 0 to 3.9063e-07.\n",
      "ImageEpoch:23\tSample:    1/35376\tLoss:64.2456\tAccuracy:1.00\n",
      "AudioEpoch:23\tSample:    1/35376\tLoss:64.2456\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:23\tSample:35376/35376\tLoss:61.8111\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:23\tSample:35376/35376\tLoss:61.8111\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.2992e+04 2.1000e+01]\n",
      " [7.9000e+01 2.2840e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:23\tSample:  472/  472\tLoss:0.3561\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "ImageEpoch:24\tSample:    1/35376\tLoss:53.3944\tAccuracy:1.00\n",
      "AudioEpoch:24\tSample:    1/35376\tLoss:53.3944\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:24\tSample:35376/35376\tLoss:61.7927\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:24\tSample:35376/35376\tLoss:61.7927\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3001e+04 1.7000e+01]\n",
      " [9.5000e+01 2.2630e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:24\tSample:  472/  472\tLoss:0.3659\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 22.  11.]]\n",
      "save!!\n",
      "ImageEpoch:25\tSample:    1/35376\tLoss:61.1453\tAccuracy:1.00\n",
      "AudioEpoch:25\tSample:    1/35376\tLoss:61.1453\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:25\tSample:35376/35376\tLoss:61.2744\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:25\tSample:35376/35376\tLoss:61.2744\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3067e+04 2.0000e+01]\n",
      " [9.5000e+01 2.1940e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:25\tSample:  472/  472\tLoss:0.3592\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 20.  13.]]\n",
      "save!!\n",
      "Epoch    25: reducing learning rate of group 0 to 1.9531e-07.\n",
      "Epoch    25: reducing learning rate of group 0 to 1.9531e-07.\n",
      "ImageEpoch:26\tSample:    1/35376\tLoss:60.7154\tAccuracy:1.00\n",
      "AudioEpoch:26\tSample:    1/35376\tLoss:60.7154\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:26\tSample:35376/35376\tLoss:61.5297\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:26\tSample:35376/35376\tLoss:61.5297\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3072e+04 2.0000e+01]\n",
      " [8.6000e+01 2.1980e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:26\tSample:  472/  472\tLoss:0.3990\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 24.   9.]]\n",
      "save!!\n",
      "ImageEpoch:27\tSample:    1/35376\tLoss:62.9397\tAccuracy:1.00\n",
      "AudioEpoch:27\tSample:    1/35376\tLoss:62.9397\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:27\tSample:35376/35376\tLoss:61.6288\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:27\tSample:35376/35376\tLoss:61.6288\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3071e+04 1.3000e+01]\n",
      " [7.2000e+01 2.2200e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:27\tSample:  472/  472\tLoss:0.4202\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 25.   8.]]\n",
      "save!!\n",
      "ImageEpoch:28\tSample:    1/35376\tLoss:52.7341\tAccuracy:1.00\n",
      "AudioEpoch:28\tSample:    1/35376\tLoss:52.7341\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:28\tSample:35376/35376\tLoss:61.0157\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:28\tSample:35376/35376\tLoss:61.0157\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3086e+04 1.6000e+01]\n",
      " [8.7000e+01 2.1870e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:28\tSample:  472/  472\tLoss:0.4459\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 24.   9.]]\n",
      "save!!\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-07.\n",
      "ImageEpoch:29\tSample:    1/35376\tLoss:59.8164\tAccuracy:1.00\n",
      "AudioEpoch:29\tSample:    1/35376\tLoss:59.8164\tAccuracy:0.99\n",
      "Training Image\n",
      " SUMMARY EPOCH:29\tSample:35376/35376\tLoss:61.5316\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:29\tSample:35376/35376\tLoss:61.5316\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.2989e+04 1.8000e+01]\n",
      " [7.6000e+01 2.2930e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:29\tSample:  472/  472\tLoss:0.3898\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 22.  11.]]\n",
      "save!!\n",
      "ImageEpoch:30\tSample:    1/35376\tLoss:64.6061\tAccuracy:1.00\n",
      "AudioEpoch:30\tSample:    1/35376\tLoss:64.6061\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:30\tSample:35376/35376\tLoss:60.8547\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:30\tSample:35376/35376\tLoss:60.8547\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.2991e+04 2.0000e+01]\n",
      " [7.9000e+01 2.2860e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:30\tSample:  472/  472\tLoss:0.4200\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 24.   9.]]\n",
      "save!!\n",
      "ImageEpoch:31\tSample:    1/35376\tLoss:57.1404\tAccuracy:1.00\n",
      "AudioEpoch:31\tSample:    1/35376\tLoss:57.1404\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:31\tSample:35376/35376\tLoss:61.7185\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:31\tSample:35376/35376\tLoss:61.7185\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3009e+04 1.0000e+01]\n",
      " [8.6000e+01 2.2710e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:31\tSample:  472/  472\tLoss:0.3647\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 22.  11.]]\n",
      "save!!\n",
      "ImageEpoch:32\tSample:    1/35376\tLoss:57.5645\tAccuracy:1.00\n",
      "AudioEpoch:32\tSample:    1/35376\tLoss:57.5645\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:32\tSample:35376/35376\tLoss:62.3305\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:32\tSample:35376/35376\tLoss:62.3305\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3002e+04 2.3000e+01]\n",
      " [7.9000e+01 2.2720e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:32\tSample:  472/  472\tLoss:0.3559\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 22.  11.]]\n",
      "save!!\n",
      "ImageEpoch:33\tSample:    1/35376\tLoss:54.8747\tAccuracy:1.00\n",
      "AudioEpoch:33\tSample:    1/35376\tLoss:54.8747\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:33\tSample:35376/35376\tLoss:60.9478\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:33\tSample:35376/35376\tLoss:60.9478\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3056e+04 2.3000e+01]\n",
      " [8.0000e+01 2.2170e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:33\tSample:  472/  472\tLoss:0.4153\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 24.   9.]]\n",
      "save!!\n",
      "ImageEpoch:34\tSample:    1/35376\tLoss:60.5764\tAccuracy:1.00\n",
      "AudioEpoch:34\tSample:    1/35376\tLoss:60.5764\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:34\tSample:35376/35376\tLoss:61.5082\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:34\tSample:35376/35376\tLoss:61.5082\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3032e+04 2.9000e+01]\n",
      " [9.5000e+01 2.2200e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:34\tSample:  472/  472\tLoss:0.3518\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "ImageEpoch:35\tSample:    1/35376\tLoss:63.1930\tAccuracy:1.00\n",
      "AudioEpoch:35\tSample:    1/35376\tLoss:63.1930\tAccuracy:0.99\n",
      "Training Image\n",
      " SUMMARY EPOCH:35\tSample:35376/35376\tLoss:61.2843\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:35\tSample:35376/35376\tLoss:61.2843\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[3.3032e+04 2.4000e+01]\n",
      " [7.5000e+01 2.2450e+03]]\n",
      "\n",
      "Validation\n",
      " SUMMARY EPOCH:35\tSample:  472/  472\tLoss:0.3946\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[439.   0.]\n",
      " [ 24.   9.]]\n",
      "save!!\n"
     ]
    }
   ],
   "source": [
    "seed = 20\n",
    "seed_everything(seed)\n",
    "aX_tr, aX_te, ay_tr, ay_te = train_test_split(aX, ay, test_size=0.2, shuffle=True, stratify=ay, random_state=seed)\n",
    "\n",
    "num_classes = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# audio\n",
    "a_model = transfer_resNet(num_classes)\n",
    "# a_model = ResNet22(2)\n",
    "a_model.to(device)\n",
    "# image\n",
    "i_model = resnet50(pretrained=True)\n",
    "num_ftrs = i_model.fc.in_features\n",
    "i_model.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "i_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "i_model.to(device)\n",
    "cls = CLS()\n",
    "cls.to(device)\n",
    "\n",
    "batch_size = 80\n",
    "train_params = {'batch_size': batch_size,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 15}\n",
    "\n",
    "test_params = {'batch_size': batch_size,\n",
    "               'shuffle': False,\n",
    "               'num_workers': 15}\n",
    "\n",
    "optimizer = torch.optim.Adam(list(i_model.parameters()) + list(a_model.parameters()) + list(cls.parameters()), lr=0.00005)\n",
    "optimizer2 = torch.optim.Adam(list(i_model.parameters()) + list(a_model.parameters()) + list(cls.parameters()), lr=0.00005)\n",
    "                    \n",
    "train_dataset = ConcatDataset_pair(aX_tr, ay_tr, iX_tr, y_tr, mode='train')             \n",
    "val_dataset = ConcatDataset_pair(aX_te, ay_te, iX_te, y_te, mode='test')\n",
    "# test_dataset = ConcatDataset(cos_test_dataset, cx_test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, **train_params)\n",
    "test_loader = DataLoader(val_dataset, **test_params)\n",
    "\n",
    "# print(model)\n",
    "num_epochs = 35\n",
    "best_pred_loss = 1000.0\n",
    "lr_sch = ReduceLROnPlateau(optimizer, factor=0.5, patience=2, min_lr=1e-7, verbose=True)\n",
    "lr_sch2 = ReduceLROnPlateau(optimizer2, factor=0.5, patience=2, min_lr=1e-7, verbose=True)\n",
    "# lr_sch = ExponentialLR(optimizer, gamma=0.975)\n",
    "\n",
    "best_acc = 0\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    mm_pair_train(device, batch_size, a_model, i_model, cls, train_loader, optimizer, optimizer2, epoch, None)\n",
    "    val_metrics, confusion_matrix = mm_pair_valid(device, batch_size, a_model, i_model, cls, test_loader, epoch, None)\n",
    "    \n",
    "    random.shuffle(train_dataset.Training_nn)\n",
    "    random.shuffle(train_dataset.Training_np)\n",
    "    random.shuffle(train_dataset.Training_pn)\n",
    "    random.shuffle(train_dataset.Training_pp)\n",
    "    len_pp = len(train_dataset.Training_pp)\n",
    "    train_dataset.datas = train_dataset.Training_nn[:len_pp//2] + train_dataset.Training_pp[:len_pp//2] + train_dataset.Training_np[:len_pp//2] + train_dataset.Training_pn[:len_pp//2]\n",
    "    \n",
    "    if val_metrics.avg('accuracy') > 0.93:\n",
    "        best_acc = val_metrics.avg('accuracy')\n",
    "        torch.save(a_model.state_dict(), '/model/pair1/a_model_' + str(best_acc)[:5] + '_' +str(val_metrics.avg('accuracy'))[:5])\n",
    "        torch.save(i_model.state_dict(), '/model/pair1/i_model_' + str(best_acc)[:5] + '_' +str(val_metrics.avg('accuracy'))[:5])\n",
    "        print('save!!')\n",
    "                   \n",
    "    lr_sch.step(val_metrics.avg('loss'))\n",
    "    lr_sch2.step(val_metrics.avg('loss'))\n",
    "#     lr_sch.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_ce + (1 - alpha) * a_ce + alpha * csa 0.5 / 0.00005 / mel\n",
    "# shuffle // 10 -> 6708 (random) @save3 pretrain x\n",
    "train examples =  259 [130 129]\n",
    "test examples =  65 [32 33]\n",
    "Training Image\n",
    " SUMMARY EPOCH:32\tSample: 6708/ 6708\tLoss:32.9175\tAccuracy:1.00\n",
    "\n",
    "Training Audio\n",
    " SUMMARY EPOCH:32\tSample: 6708/ 6708\tLoss:32.9175\tAccuracy:1.00\n",
    "\n",
    "A_Confusion Matrix\n",
    "[[3.374e+03 2.000e+00]\n",
    " [2.200e+01 3.310e+03]]\n",
    "\n",
    "Image: Validation\n",
    " SUMMARY EPOCH:32\tSample: 1579/ 1579\tLoss:0.1712\tAccuracy:0.95\n",
    "\n",
    "Confusion Matrix\n",
    "[[1415.   64.]\n",
    " [  19.   81.]]\n",
    "Audio: Validation\n",
    " SUMMARY EPOCH:32\tSample:   65/   65\tLoss:0.3008\tAccuracy:0.83\n",
    "\n",
    "Confusion Matrix\n",
    "[[28.  4.]\n",
    " [ 7. 26.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_ce + (1 - alpha) * a_ce + alpha * csa 0.5 / 0.00005 / mel\n",
    "# shuffle // 10 -> 6708 (random) @save2 pretrain x\n",
    "Image: Validation\n",
    " SUMMARY EPOCH: 8\tSample: 1579/ 1579\tLoss:0.3632\tAccuracy:0.88\n",
    "\n",
    "Confusion Matrix\n",
    "[[1305.  174.]\n",
    " [  13.   87.]]\n",
    "Audio: Validation\n",
    " SUMMARY EPOCH: 8\tSample:   65/   65\tLoss:0.1928\tAccuracy:0.86\n",
    "\n",
    "Confusion Matrix\n",
    "[[27.  5.]\n",
    " [ 4. 29.]]\n",
    "save!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_ce + (1 - alpha) * a_ce + alpha * csa 0.7 / 0.00005 / mel\n",
    "# shuffle // 10 -> 6708 (random) @save1\n",
    "Image: Validation\n",
    " SUMMARY EPOCH:29\tSample: 1579/ 1579\tLoss:0.3980\tAccuracy:0.87\n",
    "\n",
    "Confusion Matrix\n",
    "[[1288.  191.]\n",
    " [  10.   90.]]\n",
    "Audio: Validation\n",
    " SUMMARY EPOCH:29\tSample:   65/   65\tLoss:0.5410\tAccuracy:0.80\n",
    "\n",
    "Confusion Matrix\n",
    "[[26.  6.]\n",
    " [ 7. 26.]]\n",
    "save!!\n",
    "# i_ce + (1 - alpha) * a_ce + alpha * csa 0.5 / 0.00005 / mel\n",
    "# shuffle // 10 -> 6708 (random)\n",
    "Training Image\n",
    " SUMMARY EPOCH:29\tSample: 6708/ 6708\tLoss:45.2970\tAccuracy:1.00\n",
    "\n",
    "Training Audio\n",
    " SUMMARY EPOCH:29\tSample: 6708/ 6708\tLoss:45.2970\tAccuracy:0.98\n",
    "\n",
    "A_Confusion Matrix\n",
    "[[3322.   64.]\n",
    " [ 102. 3220.]]\n",
    "\n",
    "Image: Validation\n",
    " SUMMARY EPOCH:29\tSample: 1579/ 1579\tLoss:0.2261\tAccuracy:0.93\n",
    "\n",
    "Confusion Matrix\n",
    "[[1388.   91.]\n",
    " [  14.   86.]]\n",
    "Audio: Validation\n",
    " SUMMARY EPOCH:29\tSample:   65/   65\tLoss:0.5479\tAccuracy:0.80\n",
    "\n",
    "Confusion Matrix\n",
    "[[26.  6.]\n",
    " [ 7. 26.]]\n",
    "# i_ce + (1 - alpha) * a_ce + alpha * csa 0.5 / 0.00005 / mel\n",
    "# shuffle // 10 -> 6708\n",
    "Training Image\n",
    " SUMMARY EPOCH:18\tSample: 6708/ 6708\tLoss:39.7886\tAccuracy:1.00\n",
    "\n",
    "Training Audio\n",
    " SUMMARY EPOCH:18\tSample: 6708/ 6708\tLoss:39.7886\tAccuracy:0.99\n",
    "\n",
    "A_Confusion Matrix\n",
    "[[3313.   30.]\n",
    " [  36. 3329.]]\n",
    "\n",
    "Image: Validation\n",
    " SUMMARY EPOCH:18\tSample: 1579/ 1579\tLoss:0.2895\tAccuracy:0.90\n",
    "\n",
    "Confusion Matrix\n",
    "[[1338.  141.]\n",
    " [  11.   89.]]\n",
    "Audio: Validation\n",
    " SUMMARY EPOCH:18\tSample:   65/   65\tLoss:0.7218\tAccuracy:0.80\n",
    "\n",
    "Confusion Matrix\n",
    "[[26.  6.]\n",
    " [ 7. 26.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics, confusion_matrix = validation(device, batch_size, num_classes, model, test_loader, epoch, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
