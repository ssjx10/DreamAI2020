{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import librosa\n",
    "import torchaudio\n",
    "import torchaudio.transforms as AT\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from covidxdataset import COVIDxDataset, COVIDxDataset2\n",
    "from audiodataset import CoswaraDataset, ConcatDataset, CoswaraDataset2, CoswaraDataset3\n",
    "import util as util\n",
    "from util import Mel2Samp\n",
    "from train import train, validation, mm_train\n",
    "from model import transfer_resNet, ResNet54, ResNet22, ResNet38, resnet50, MMNet\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio\n",
    "a_model = transfer_resNet(2)\n",
    "# a_model = ResNet22(2)\n",
    "\n",
    "# image\n",
    "i_model = resnet50()\n",
    "num_ftrs = i_model.fc.in_features\n",
    "i_model.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "i_model.fc = nn.Linear(num_ftrs, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_model.load_state_dict(torch.load('model/save3/a_model_0.830_0.955'))\n",
    "i_model.load_state_dict(torch.load('model/save3/i_model_0.830_0.955'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmnet = MMNet(a_model, i_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mmnet.state_dict(), './model/mmnet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from util import read_filepaths\n",
    "def load_image(img_path, dim):\n",
    "    if not os.path.exists(img_path):\n",
    "        print(\"IMAGE DOES NOT EXIST {}\".format(img_path))\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    image = image.resize(dim)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = '/data/CovidX_dataset/test_split.txt'\n",
    "trainfile = '/data/CovidX_dataset/train_split.txt'\n",
    "dataset_path='/data/CovidX_dataset/'\n",
    "\n",
    "paths, labels = read_filepaths(testfile)\n",
    "imgs = []\n",
    "for path in paths:\n",
    "    image = load_image(dataset_path + 'test/' + path, (224,224))\n",
    "    imgs.append(np.array(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('audios_full.npz', allow_pickle=True)\n",
    "aX, ay = data['x'], data['y']\n",
    "data = np.load('images_tr_full.npz', allow_pickle=True)\n",
    "iX_tr, y_tr = data['x'], data['y']\n",
    "data = np.load('images_test.npz', allow_pickle=True)\n",
    "iX_te, y_te = data['x'], data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test examples =  472 [439  33]\n",
      "test examples =  1579 [1479  100]\n",
      "train audio examples =  1886 [1753  133]\n",
      "train image examples =  13957 [13440   517]\n",
      "Class P :  23629081  N :  2693821\n",
      "ImageEpoch: 1\tSample:    1/34380\tLoss:1689.0861\tAccuracy:0.35\n",
      "AudioEpoch: 1\tSample:    1/34380\tLoss:1689.0861\tAccuracy:0.50\n",
      "Training Image\n",
      " SUMMARY EPOCH: 1\tSample:34380/34380\tLoss:175.5489\tAccuracy:0.94\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 1\tSample:34380/34380\tLoss:175.5489\tAccuracy:0.50\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[   97. 17093.]\n",
      " [   95. 17095.]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH: 1\tSample: 1579/ 1579\tLoss:0.0788\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1448.   31.]\n",
      " [  13.   87.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH: 1\tSample:  472/  472\tLoss:1.9774\tAccuracy:0.07\n",
      "\n",
      "Confusion Matrix\n",
      "[[  0. 439.]\n",
      " [  0.  33.]]\n",
      "ImageEpoch: 2\tSample:    1/34380\tLoss:145.9898\tAccuracy:0.97\n",
      "AudioEpoch: 2\tSample:    1/34380\tLoss:145.9898\tAccuracy:0.46\n",
      "Training Image\n",
      " SUMMARY EPOCH: 2\tSample:34380/34380\tLoss:130.2781\tAccuracy:0.98\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 2\tSample:34380/34380\tLoss:130.2781\tAccuracy:0.58\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[ 2879. 14311.]\n",
      " [   28. 17162.]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH: 2\tSample: 1579/ 1579\tLoss:0.3409\tAccuracy:0.89\n",
      "\n",
      "Confusion Matrix\n",
      "[[1311.  168.]\n",
      " [   2.   98.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH: 2\tSample:  472/  472\tLoss:0.9164\tAccuracy:0.52\n",
      "\n",
      "Confusion Matrix\n",
      "[[217. 222.]\n",
      " [  4.  29.]]\n",
      "ImageEpoch: 3\tSample:    1/34380\tLoss:111.9804\tAccuracy:0.99\n",
      "AudioEpoch: 3\tSample:    1/34380\tLoss:111.9804\tAccuracy:0.77\n",
      "Training Image\n",
      " SUMMARY EPOCH: 3\tSample:34380/34380\tLoss:101.6610\tAccuracy:0.99\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 3\tSample:34380/34380\tLoss:101.6610\tAccuracy:0.90\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[13955.  3235.]\n",
      " [   60. 17130.]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH: 3\tSample: 1579/ 1579\tLoss:0.1202\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[1423.   56.]\n",
      " [   6.   94.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH: 3\tSample:  472/  472\tLoss:0.3910\tAccuracy:0.85\n",
      "\n",
      "Confusion Matrix\n",
      "[[384.  55.]\n",
      " [ 14.  19.]]\n",
      "ImageEpoch: 4\tSample:    1/34380\tLoss:80.7249\tAccuracy:1.00\n",
      "AudioEpoch: 4\tSample:    1/34380\tLoss:80.7249\tAccuracy:0.98\n",
      "Training Image\n",
      " SUMMARY EPOCH: 4\tSample:34380/34380\tLoss:84.7054\tAccuracy:0.99\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 4\tSample:34380/34380\tLoss:84.7054\tAccuracy:0.98\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[16402.   788.]\n",
      " [   23. 17167.]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH: 4\tSample: 1579/ 1579\tLoss:0.1919\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[1370.  109.]\n",
      " [   5.   95.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH: 4\tSample:  472/  472\tLoss:0.3257\tAccuracy:0.88\n",
      "\n",
      "Confusion Matrix\n",
      "[[393.  46.]\n",
      " [ 11.  22.]]\n",
      "save!!\n",
      "ImageEpoch: 5\tSample:    1/34380\tLoss:78.6462\tAccuracy:1.00\n",
      "AudioEpoch: 5\tSample:    1/34380\tLoss:78.6462\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH: 5\tSample:34380/34380\tLoss:81.1978\tAccuracy:0.99\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 5\tSample:34380/34380\tLoss:81.1978\tAccuracy:0.99\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.6888e+04 3.0200e+02]\n",
      " [1.1000e+01 1.7179e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH: 5\tSample: 1579/ 1579\tLoss:0.1154\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[1421.   58.]\n",
      " [   8.   92.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH: 5\tSample:  472/  472\tLoss:0.2578\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[425.  14.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "ImageEpoch: 6\tSample:    1/34380\tLoss:75.5879\tAccuracy:1.00\n",
      "AudioEpoch: 6\tSample:    1/34380\tLoss:75.5879\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH: 6\tSample:34380/34380\tLoss:76.5431\tAccuracy:0.99\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 6\tSample:34380/34380\tLoss:76.5431\tAccuracy:0.99\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7013e+04 1.7700e+02]\n",
      " [7.0000e+00 1.7183e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH: 6\tSample: 1579/ 1579\tLoss:0.1613\tAccuracy:0.94\n",
      "\n",
      "Confusion Matrix\n",
      "[[1390.   89.]\n",
      " [   4.   96.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH: 6\tSample:  472/  472\tLoss:0.2929\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[423.  16.]\n",
      " [ 19.  14.]]\n",
      "save!!\n",
      "ImageEpoch: 7\tSample:    1/34380\tLoss:93.7997\tAccuracy:1.00\n",
      "AudioEpoch: 7\tSample:    1/34380\tLoss:93.7997\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH: 7\tSample:34380/34380\tLoss:71.7836\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 7\tSample:34380/34380\tLoss:71.7836\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7106e+04 8.4000e+01]\n",
      " [1.0000e+01 1.7180e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH: 7\tSample: 1579/ 1579\tLoss:0.2290\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[1366.  113.]\n",
      " [   5.   95.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH: 7\tSample:  472/  472\tLoss:0.3545\tAccuracy:0.90\n",
      "\n",
      "Confusion Matrix\n",
      "[[412.  27.]\n",
      " [ 19.  14.]]\n",
      "save!!\n",
      "ImageEpoch: 8\tSample:    1/34380\tLoss:67.8598\tAccuracy:1.00\n",
      "AudioEpoch: 8\tSample:    1/34380\tLoss:67.8598\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH: 8\tSample:34380/34380\tLoss:71.2978\tAccuracy:0.99\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 8\tSample:34380/34380\tLoss:71.2978\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7145e+04 4.5000e+01]\n",
      " [2.0000e+00 1.7188e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH: 8\tSample: 1579/ 1579\tLoss:0.1366\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[1406.   73.]\n",
      " [   5.   95.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH: 8\tSample:  472/  472\tLoss:0.2955\tAccuracy:0.94\n",
      "\n",
      "Confusion Matrix\n",
      "[[433.   6.]\n",
      " [ 23.  10.]]\n",
      "save!!\n",
      "Epoch     8: reducing learning rate of group 0 to 2.5000e-05.\n",
      "ImageEpoch: 9\tSample:    1/34380\tLoss:61.1308\tAccuracy:1.00\n",
      "AudioEpoch: 9\tSample:    1/34380\tLoss:61.1308\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH: 9\tSample:34380/34380\tLoss:69.5865\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH: 9\tSample:34380/34380\tLoss:69.5865\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7156e+04 3.4000e+01]\n",
      " [4.0000e+00 1.7186e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH: 9\tSample: 1579/ 1579\tLoss:0.1069\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[1425.   54.]\n",
      " [   9.   91.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH: 9\tSample:  472/  472\tLoss:0.2945\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[429.  10.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "ImageEpoch:10\tSample:    1/34380\tLoss:60.7523\tAccuracy:1.00\n",
      "AudioEpoch:10\tSample:    1/34380\tLoss:60.7523\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:10\tSample:34380/34380\tLoss:62.6761\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:10\tSample:34380/34380\tLoss:62.6761\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7165e+04 2.5000e+01]\n",
      " [1.0000e+00 1.7189e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:10\tSample: 1579/ 1579\tLoss:0.0935\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1437.   42.]\n",
      " [  11.   89.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:10\tSample:  472/  472\tLoss:0.3315\tAccuracy:0.92\n",
      "\n",
      "Confusion Matrix\n",
      "[[418.  21.]\n",
      " [ 18.  15.]]\n",
      "save!!\n",
      "ImageEpoch:11\tSample:    1/34380\tLoss:62.9186\tAccuracy:1.00\n",
      "AudioEpoch:11\tSample:    1/34380\tLoss:62.9186\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:11\tSample:34380/34380\tLoss:60.2891\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:11\tSample:34380/34380\tLoss:60.2891\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[17170.    20.]\n",
      " [    0. 17190.]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:11\tSample: 1579/ 1579\tLoss:0.0969\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[1429.   50.]\n",
      " [  11.   89.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:11\tSample:  472/  472\tLoss:0.3222\tAccuracy:0.92\n",
      "\n",
      "Confusion Matrix\n",
      "[[423.  16.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "Epoch    11: reducing learning rate of group 0 to 1.2500e-05.\n",
      "ImageEpoch:12\tSample:    1/34380\tLoss:61.3819\tAccuracy:0.99\n",
      "AudioEpoch:12\tSample:    1/34380\tLoss:61.3819\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:12\tSample:34380/34380\tLoss:56.7041\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:12\tSample:34380/34380\tLoss:56.7041\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.718e+04 1.000e+01]\n",
      " [0.000e+00 1.719e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:12\tSample: 1579/ 1579\tLoss:0.1447\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[1406.   73.]\n",
      " [   7.   93.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:12\tSample:  472/  472\tLoss:0.3072\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[426.  13.]\n",
      " [ 20.  13.]]\n",
      "save!!\n",
      "ImageEpoch:13\tSample:    1/34380\tLoss:57.1092\tAccuracy:1.00\n",
      "AudioEpoch:13\tSample:    1/34380\tLoss:57.1092\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:13\tSample:34380/34380\tLoss:56.7066\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:13\tSample:34380/34380\tLoss:56.7066\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7179e+04 1.1000e+01]\n",
      " [1.0000e+00 1.7189e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:13\tSample: 1579/ 1579\tLoss:0.1105\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[1425.   54.]\n",
      " [   8.   92.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:13\tSample:  472/  472\tLoss:0.3529\tAccuracy:0.92\n",
      "\n",
      "Confusion Matrix\n",
      "[[418.  21.]\n",
      " [ 16.  17.]]\n",
      "save!!\n",
      "ImageEpoch:14\tSample:    1/34380\tLoss:70.6077\tAccuracy:1.00\n",
      "AudioEpoch:14\tSample:    1/34380\tLoss:70.6077\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:14\tSample:34380/34380\tLoss:55.4916\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:14\tSample:34380/34380\tLoss:55.4916\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7182e+04 8.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:14\tSample: 1579/ 1579\tLoss:0.1329\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[1410.   69.]\n",
      " [   8.   92.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:14\tSample:  472/  472\tLoss:0.3104\tAccuracy:0.94\n",
      "\n",
      "Confusion Matrix\n",
      "[[428.  11.]\n",
      " [ 19.  14.]]\n",
      "save!!\n",
      "Epoch    14: reducing learning rate of group 0 to 6.2500e-06.\n",
      "ImageEpoch:15\tSample:    1/34380\tLoss:51.1609\tAccuracy:1.00\n",
      "AudioEpoch:15\tSample:    1/34380\tLoss:51.1609\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:15\tSample:34380/34380\tLoss:54.4816\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:15\tSample:34380/34380\tLoss:54.4816\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7184e+04 6.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:15\tSample: 1579/ 1579\tLoss:0.1191\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[1418.   61.]\n",
      " [   7.   93.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:15\tSample:  472/  472\tLoss:0.3256\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[426.  13.]\n",
      " [ 20.  13.]]\n",
      "save!!\n",
      "ImageEpoch:16\tSample:    1/34380\tLoss:56.1867\tAccuracy:1.00\n",
      "AudioEpoch:16\tSample:    1/34380\tLoss:56.1867\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:16\tSample:34380/34380\tLoss:53.5876\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:16\tSample:34380/34380\tLoss:53.5876\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7182e+04 8.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:16\tSample: 1579/ 1579\tLoss:0.1487\tAccuracy:0.95\n",
      "\n",
      "Confusion Matrix\n",
      "[[1406.   73.]\n",
      " [   7.   93.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:16\tSample:  472/  472\tLoss:0.3306\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[426.  13.]\n",
      " [ 20.  13.]]\n",
      "save!!\n",
      "ImageEpoch:17\tSample:    1/34380\tLoss:62.6294\tAccuracy:1.00\n",
      "AudioEpoch:17\tSample:    1/34380\tLoss:62.6294\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:17\tSample:34380/34380\tLoss:54.0765\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:17\tSample:34380/34380\tLoss:54.0765\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7184e+04 6.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:17\tSample: 1579/ 1579\tLoss:0.0951\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1436.   43.]\n",
      " [   8.   92.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:17\tSample:  472/  472\tLoss:0.3354\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[426.  13.]\n",
      " [ 19.  14.]]\n",
      "save!!\n",
      "Epoch    17: reducing learning rate of group 0 to 3.1250e-06.\n",
      "ImageEpoch:18\tSample:    1/34380\tLoss:61.6607\tAccuracy:1.00\n",
      "AudioEpoch:18\tSample:    1/34380\tLoss:61.6607\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:18\tSample:34380/34380\tLoss:53.4197\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:18\tSample:34380/34380\tLoss:53.4197\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.718e+04 1.000e+01]\n",
      " [0.000e+00 1.719e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:18\tSample: 1579/ 1579\tLoss:0.0963\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1436.   43.]\n",
      " [   8.   92.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:18\tSample:  472/  472\tLoss:0.3273\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[423.  16.]\n",
      " [ 18.  15.]]\n",
      "save!!\n",
      "ImageEpoch:19\tSample:    1/34380\tLoss:52.7800\tAccuracy:1.00\n",
      "AudioEpoch:19\tSample:    1/34380\tLoss:52.7800\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:19\tSample:34380/34380\tLoss:52.8263\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:19\tSample:34380/34380\tLoss:52.8263\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7182e+04 8.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:19\tSample: 1579/ 1579\tLoss:0.0951\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1436.   43.]\n",
      " [   9.   91.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:19\tSample:  472/  472\tLoss:0.3329\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[426.  13.]\n",
      " [ 18.  15.]]\n",
      "save!!\n",
      "ImageEpoch:20\tSample:    1/34380\tLoss:43.9658\tAccuracy:1.00\n",
      "AudioEpoch:20\tSample:    1/34380\tLoss:43.9658\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:20\tSample:34380/34380\tLoss:52.4995\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:20\tSample:34380/34380\tLoss:52.4995\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.718e+04 1.000e+01]\n",
      " [0.000e+00 1.719e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:20\tSample: 1579/ 1579\tLoss:0.0966\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1435.   44.]\n",
      " [   8.   92.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:20\tSample:  472/  472\tLoss:0.3292\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[425.  14.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "Epoch    20: reducing learning rate of group 0 to 1.5625e-06.\n",
      "ImageEpoch:21\tSample:    1/34380\tLoss:41.0531\tAccuracy:1.00\n",
      "AudioEpoch:21\tSample:    1/34380\tLoss:41.0531\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:21\tSample:34380/34380\tLoss:51.7074\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:21\tSample:34380/34380\tLoss:51.7074\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7181e+04 9.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:21\tSample: 1579/ 1579\tLoss:0.0804\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1443.   36.]\n",
      " [  10.   90.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:21\tSample:  472/  472\tLoss:0.3459\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[427.  12.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "ImageEpoch:22\tSample:    1/34380\tLoss:56.3665\tAccuracy:1.00\n",
      "AudioEpoch:22\tSample:    1/34380\tLoss:56.3665\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:22\tSample:34380/34380\tLoss:51.9305\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:22\tSample:34380/34380\tLoss:51.9305\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7182e+04 8.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:22\tSample: 1579/ 1579\tLoss:0.0842\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1441.   38.]\n",
      " [   8.   92.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:22\tSample:  472/  472\tLoss:0.3424\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[428.  11.]\n",
      " [ 22.  11.]]\n",
      "save!!\n",
      "ImageEpoch:23\tSample:    1/34380\tLoss:53.8788\tAccuracy:1.00\n",
      "AudioEpoch:23\tSample:    1/34380\tLoss:53.8788\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:23\tSample:34380/34380\tLoss:51.1546\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:23\tSample:34380/34380\tLoss:51.1546\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7185e+04 5.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:23\tSample: 1579/ 1579\tLoss:0.0991\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1436.   43.]\n",
      " [   8.   92.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:23\tSample:  472/  472\tLoss:0.3374\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[426.  13.]\n",
      " [ 19.  14.]]\n",
      "save!!\n",
      "Epoch    23: reducing learning rate of group 0 to 7.8125e-07.\n",
      "ImageEpoch:24\tSample:    1/34380\tLoss:69.5702\tAccuracy:1.00\n",
      "AudioEpoch:24\tSample:    1/34380\tLoss:69.5702\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:24\tSample:34380/34380\tLoss:51.9150\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:24\tSample:34380/34380\tLoss:51.9150\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7187e+04 3.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:24\tSample: 1579/ 1579\tLoss:0.0764\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1449.   30.]\n",
      " [  10.   90.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:24\tSample:  472/  472\tLoss:0.3345\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[426.  13.]\n",
      " [ 20.  13.]]\n",
      "save!!\n",
      "ImageEpoch:25\tSample:    1/34380\tLoss:50.4023\tAccuracy:1.00\n",
      "AudioEpoch:25\tSample:    1/34380\tLoss:50.4023\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:25\tSample:34380/34380\tLoss:51.6881\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:25\tSample:34380/34380\tLoss:51.6881\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7188e+04 2.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:25\tSample: 1579/ 1579\tLoss:0.0948\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1433.   46.]\n",
      " [   9.   91.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:25\tSample:  472/  472\tLoss:0.3458\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[429.  10.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "ImageEpoch:26\tSample:    1/34380\tLoss:60.7310\tAccuracy:1.00\n",
      "AudioEpoch:26\tSample:    1/34380\tLoss:60.7310\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:26\tSample:34380/34380\tLoss:51.2569\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:26\tSample:34380/34380\tLoss:51.2569\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7188e+04 2.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:26\tSample: 1579/ 1579\tLoss:0.0829\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1443.   36.]\n",
      " [  10.   90.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:26\tSample:  472/  472\tLoss:0.3369\tAccuracy:0.94\n",
      "\n",
      "Confusion Matrix\n",
      "[[432.   7.]\n",
      " [ 22.  11.]]\n",
      "save!!\n",
      "Epoch    26: reducing learning rate of group 0 to 3.9063e-07.\n",
      "ImageEpoch:27\tSample:    1/34380\tLoss:60.7443\tAccuracy:1.00\n",
      "AudioEpoch:27\tSample:    1/34380\tLoss:60.7443\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:27\tSample:34380/34380\tLoss:51.8591\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:27\tSample:34380/34380\tLoss:51.8591\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7185e+04 5.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:27\tSample: 1579/ 1579\tLoss:0.0874\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1438.   41.]\n",
      " [  10.   90.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:27\tSample:  472/  472\tLoss:0.3318\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[428.  11.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "ImageEpoch:28\tSample:    1/34380\tLoss:45.9629\tAccuracy:1.00\n",
      "AudioEpoch:28\tSample:    1/34380\tLoss:45.9629\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:28\tSample:34380/34380\tLoss:52.0355\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:28\tSample:34380/34380\tLoss:52.0355\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7186e+04 4.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:28\tSample: 1579/ 1579\tLoss:0.0638\tAccuracy:0.98\n",
      "\n",
      "Confusion Matrix\n",
      "[[1455.   24.]\n",
      " [  13.   87.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:28\tSample:  472/  472\tLoss:0.3315\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[428.  11.]\n",
      " [ 22.  11.]]\n",
      "save!!\n",
      "ImageEpoch:29\tSample:    1/34380\tLoss:48.0841\tAccuracy:1.00\n",
      "AudioEpoch:29\tSample:    1/34380\tLoss:48.0841\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:29\tSample:34380/34380\tLoss:51.0999\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:29\tSample:34380/34380\tLoss:51.0999\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7187e+04 3.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:29\tSample: 1579/ 1579\tLoss:0.0895\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1437.   42.]\n",
      " [   9.   91.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:29\tSample:  472/  472\tLoss:0.3323\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[427.  12.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "Epoch    29: reducing learning rate of group 0 to 1.9531e-07.\n",
      "ImageEpoch:30\tSample:    1/34380\tLoss:43.3325\tAccuracy:1.00\n",
      "AudioEpoch:30\tSample:    1/34380\tLoss:43.3325\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:30\tSample:34380/34380\tLoss:51.9380\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:30\tSample:34380/34380\tLoss:51.9380\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7186e+04 4.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:30\tSample: 1579/ 1579\tLoss:0.0836\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1439.   40.]\n",
      " [  10.   90.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:30\tSample:  472/  472\tLoss:0.3332\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[429.  10.]\n",
      " [ 22.  11.]]\n",
      "save!!\n",
      "ImageEpoch:31\tSample:    1/34380\tLoss:47.3228\tAccuracy:1.00\n",
      "AudioEpoch:31\tSample:    1/34380\tLoss:47.3228\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:31\tSample:34380/34380\tLoss:51.2846\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:31\tSample:34380/34380\tLoss:51.2846\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[17190.     0.]\n",
      " [    0. 17190.]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:31\tSample: 1579/ 1579\tLoss:0.0961\tAccuracy:0.97\n",
      "\n",
      "Confusion Matrix\n",
      "[[1435.   44.]\n",
      " [   8.   92.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:31\tSample:  472/  472\tLoss:0.3367\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[426.  13.]\n",
      " [ 20.  13.]]\n",
      "save!!\n",
      "ImageEpoch:32\tSample:    1/34380\tLoss:57.0068\tAccuracy:1.00\n",
      "AudioEpoch:32\tSample:    1/34380\tLoss:57.0068\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:32\tSample:34380/34380\tLoss:51.4396\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:32\tSample:34380/34380\tLoss:51.4396\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[17190.     0.]\n",
      " [    0. 17190.]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:32\tSample: 1579/ 1579\tLoss:0.0726\tAccuracy:0.98\n",
      "\n",
      "Confusion Matrix\n",
      "[[1453.   26.]\n",
      " [  11.   89.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:32\tSample:  472/  472\tLoss:0.3356\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[427.  12.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-07.\n",
      "ImageEpoch:33\tSample:    1/34380\tLoss:49.9770\tAccuracy:1.00\n",
      "AudioEpoch:33\tSample:    1/34380\tLoss:49.9770\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:33\tSample:34380/34380\tLoss:51.5370\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:33\tSample:34380/34380\tLoss:51.5370\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7185e+04 5.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:33\tSample: 1579/ 1579\tLoss:0.0664\tAccuracy:0.98\n",
      "\n",
      "Confusion Matrix\n",
      "[[1457.   22.]\n",
      " [  14.   86.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:33\tSample:  472/  472\tLoss:0.3310\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[428.  11.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "ImageEpoch:34\tSample:    1/34380\tLoss:48.7657\tAccuracy:1.00\n",
      "AudioEpoch:34\tSample:    1/34380\tLoss:48.7657\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:34\tSample:34380/34380\tLoss:51.0153\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:34\tSample:34380/34380\tLoss:51.0153\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7188e+04 2.0000e+00]\n",
      " [0.0000e+00 1.7190e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:34\tSample: 1579/ 1579\tLoss:0.0722\tAccuracy:0.98\n",
      "\n",
      "Confusion Matrix\n",
      "[[1452.   27.]\n",
      " [  12.   88.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:34\tSample:  472/  472\tLoss:0.3273\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[429.  10.]\n",
      " [ 21.  12.]]\n",
      "save!!\n",
      "ImageEpoch:35\tSample:    1/34380\tLoss:56.8649\tAccuracy:1.00\n",
      "AudioEpoch:35\tSample:    1/34380\tLoss:56.8649\tAccuracy:1.00\n",
      "Training Image\n",
      " SUMMARY EPOCH:35\tSample:34380/34380\tLoss:52.1420\tAccuracy:1.00\n",
      "\n",
      "Training Audio\n",
      " SUMMARY EPOCH:35\tSample:34380/34380\tLoss:52.1420\tAccuracy:1.00\n",
      "\n",
      "A_Confusion Matrix\n",
      "[[1.7184e+04 6.0000e+00]\n",
      " [1.0000e+00 1.7189e+04]]\n",
      "\n",
      "Image: Validation\n",
      " SUMMARY EPOCH:35\tSample: 1579/ 1579\tLoss:0.1313\tAccuracy:0.96\n",
      "\n",
      "Confusion Matrix\n",
      "[[1416.   63.]\n",
      " [   7.   93.]]\n",
      "Audio: Validation\n",
      " SUMMARY EPOCH:35\tSample:  472/  472\tLoss:0.3356\tAccuracy:0.93\n",
      "\n",
      "Confusion Matrix\n",
      "[[427.  12.]\n",
      " [ 21.  12.]]\n",
      "save!!\n"
     ]
    }
   ],
   "source": [
    "seed = 20\n",
    "seed_everything(seed)\n",
    "aX_tr, aX_te, ay_tr, ay_te = train_test_split(aX, ay, test_size=0.2, shuffle=True, stratify=ay, random_state=seed)\n",
    "\n",
    "num_classes = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# audio\n",
    "a_model = transfer_resNet(num_classes)\n",
    "# a_model = ResNet22(2)\n",
    "a_model.to(device)\n",
    "# image\n",
    "i_model = resnet50(pretrained=True)\n",
    "num_ftrs = i_model.fc.in_features\n",
    "i_model.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "i_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "i_model.to(device)\n",
    "\n",
    "batch_size = 96\n",
    "train_params = {'batch_size': batch_size,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 15}\n",
    "\n",
    "test_params = {'batch_size': batch_size,\n",
    "               'shuffle': False,\n",
    "               'num_workers': 15}\n",
    "\n",
    "optimizer = torch.optim.Adam(list(i_model.parameters()) + list(a_model.parameters()), lr=0.00005)\n",
    "\n",
    "# cos_train_dataset = CoswaraDataset(mode='train', n_classes=num_classes, segment_length=16000*4)\n",
    "# cos_val_dataset = CoswaraDataset(mode='valid', n_classes=num_classes, segment_length=16000*4)\n",
    "# cos_test_dataset = CoswaraDataset(mode='test', n_classes=num_classes, segment_length=16000*4)\n",
    "\n",
    "# cos_train_dataset = CoswaraDataset2(x,y, mode='train', segment_length=16000*4)\n",
    "# cos_test_dataset = CoswaraDataset2(x_test,y_test, mode='test', segment_length=16000*4)\n",
    "\n",
    "# cos_train_dataset = CoswaraDataset3(aX_tr, ay_tr, mode='train')\n",
    "cos_test_dataset = CoswaraDataset2(aX_te, ay_te, mode='test')\n",
    "                                    \n",
    "# cx_train_dataset = COVIDxDataset(mode='train', n_classes=num_classes, dim=(224, 224))\n",
    "# cx_val_dataset = COVIDxDataset(mode='valid', n_classes=num_classes, dim=(224, 224))\n",
    "# cx_test_dataset = COVIDxDataset(mode='test', n_classes=num_classes, dim=(224, 224))\n",
    "\n",
    "# cx_train_dataset = COVIDxDataset2(iX_tr, y_tr, mode='train')\n",
    "cx_test_dataset = COVIDxDataset2(iX_te, y_te, mode='test')\n",
    "    \n",
    "train_dataset = ConcatDataset(aX_tr, ay_tr, iX_tr, y_tr, mode='train')\n",
    "# val_dataset = ConcatDataset(cos_val_dataset, cx_val_dataset)\n",
    "# test_dataset = ConcatDataset(cos_test_dataset, cx_test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, **train_params)\n",
    "# val_loader = DataLoader(val_dataset, **test_params)\n",
    "###\n",
    "i_test_loader = DataLoader(cx_test_dataset, **test_params)\n",
    "o_test_loader = DataLoader(cos_test_dataset, **test_params)\n",
    "\n",
    "# print(model)\n",
    "num_epochs = 35\n",
    "best_pred_loss = 1000.0\n",
    "lr_sch = ReduceLROnPlateau(optimizer, factor=0.5, patience=2, min_lr=1e-7, verbose=True)\n",
    "# lr_sch = ExponentialLR(optimizer, gamma=0.975)\n",
    "\n",
    "best_acc = 0\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    mm_train(device, batch_size, a_model, i_model, train_loader, optimizer, epoch, None)\n",
    "    print('Image:', end=' ')\n",
    "    i_val_metrics, confusion_matrix = validation(device, batch_size, num_classes, i_model, i_test_loader, epoch, None)\n",
    "    print('Audio:', end=' ')\n",
    "    val_metrics, confusion_matrix = validation(device, batch_size, num_classes, a_model, o_test_loader, epoch, None)\n",
    "    \n",
    "    \n",
    "    random.shuffle(train_dataset.Training_nn)\n",
    "    random.shuffle(train_dataset.Training_np)\n",
    "    random.shuffle(train_dataset.Training_pn)\n",
    "    random.shuffle(train_dataset.Training_pp)\n",
    "    len_pp = len(train_dataset.Training_pp)\n",
    "    train_dataset.datas = train_dataset.Training_nn[:len_pp//8] + train_dataset.Training_pp[:len_pp//8] + train_dataset.Training_np[:len_pp//8] + train_dataset.Training_pn[:len_pp//8]\n",
    "    \n",
    "    if val_metrics.avg('accuracy') > 0.87:\n",
    "        best_acc = val_metrics.avg('accuracy')\n",
    "        torch.save(a_model.state_dict(), '/model/save1/f2_a_model_' + str(best_acc)[:5] + '_' +str(val_metrics.avg('accuracy'))[:5])\n",
    "        torch.save(i_model.state_dict(), '/model/save1/f2_i_model_' + str(best_acc)[:5] + '_' +str(i_val_metrics.avg('accuracy'))[:5])\n",
    "        print('save!!')\n",
    "                   \n",
    "    lr_sch.step(val_metrics.avg('loss'))\n",
    "#     lr_sch.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
